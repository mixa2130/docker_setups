### Парадигма MapReduce

#### 1. Задача на подсчёт кол-ва встречаемости слов в тексте (WordCount)

Логика решения задачи
1. **Read**. Считывает данные из входного пути, разбивает на сплиты (обычно размер сплита = размер HDFS-блока), распределяет сплиты по мапперам.
2. **Mapper**. Получает на вход данные построчно и разбивает по словам. На выходе пары `(слово, 1)`.
3. **Shuffle & sort**. Сортирует данные по ключу (слово) и передаёт их в таком виде, чтоб все строки с одинаковыми ключами гарантированно пошли на 1 reducer.
3. **Reducer**. Суммирует кол-ва слов с одинаковыми ключами. Ключи приходят упорядоченно, т.е. не может прийти k2 пока не закончились пары с k1. На выходе пары `(слово, кол-во)`.

```bash
OUT_DIR="streaming_wc_result"
NUM_REDUCERS=8

hadoop fs -rm -r -skipTrash $OUT_DIR*  # удаляем результаты предыдущего запуска (HDFS не перезаписывает данные поэтому без удаления выдаст ошибку о том, что путь занят).

yarn jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-streaming.jar \  # подключаем jar-файл с инструментами Hadoop Streaming
    -D mapreduce.job.reduces=${NUM_REDUCERS} \  # устанавливаем кол-во reducer'ов в задаче
    -files mapper.py,reducer.py \  # добавляем файлы в distributed cache чтоб каждая нода имела к ним доступ
    -mapper mapper.py \  # для такой записи файлы должны быть исполняемыми
    -reducer reducer.py \  # в противном случае пишем `python mapper.py`, `bash mapper.py` в зависимости о того, на чём написан код.
    -input /data/wiki/en_articles_part \  # входны и выходные данные
    -output $OUT_DIR # относительный путь (= /user/par2018XX/${OUT_DIR})

# Проверка результата.
# Каждый reducer генерирует вывод в свой файл. Файлы имеют вид `part-XXXXX`.
for num in `seq 0 $(($NUM_REDUCERS - 1))`
do
    hdfs dfs -cat ${OUT_DIR}/part-0000$num | head  # Выводим 1-е 10 строк из каждого файла. 
done
```
Исходники: `/home/velkerr/sber-hadoop2021-1/materials/02-mapreduce/01-wordcount`.

Смотрим на ApplicationMaster. http://localhost:8088/cluster (если зашли без переброса порта 8088 - перезайдите ещё раз). Можно отслеживать статус выполнения задачи.
Ссылка "History" недоступна даже при перебросе портов. Нужно скопировать её в отдельную вкладку браузера и заменить вручную mipt-master на localhost.

Чтоб отличать свою задачу от других, удобно присвоить ей имя. Для этого в Streaming driver дописываем: `-D mapred.job.name="my_wordcout_example"`.

**Отключим Reduce-стадию у задачи и запустим её. Что видим?**

#### 2. Отладка MapReduce-задач

**Эмуляция работы Hadoop с помощью bash-скрипта.**

1. Скачиваем часть данных себе локально из HDFS (можно найти в /home/velkerr/sber-hadoop2021-1/materials/02-mapreduce/01-wordcount/in).
2. Запускаем `cat my_data.txt | ./mapper.py | sort | ./reducer.py`.

Исходник: `/home/velkerr/sber-hadoop2021-1/materials/02-mapreduce/01-wordcount/test_local.sh`

**Запуск Hadoop в локальном режиме** 

1. Запуск такой же, как и в распределённом, но нужно прописать после "yarn" специальный конфиг: `--config /opt/cloudera/parcels/CDH/etc/hadoop/conf.empty`
2. При этом программа будет читать и писать уже не в HDFS, а в локальную файловую систему.

При локальном запуске reducer будет всегда 1 (вне зависимости от кол-ва в streaming-драйвере).

Исходник: `/home/velkerr/sber-hadoop2021-1/materials/02-mapreduce/01-wordcount/run_local.sh`

#### 3. Задача
В выводе примера можно было увидеть много мусора, который словами не являлся. Теперь ваша задача:
- избавиться от пунктуации при подсчёте слов.
- не учитывать регистр при подсчёте.

#### 4. Combiner
Бывает так, что на выходе мапперов имеются данные, пригодные для аггрегации. Если мы их саггрегируем **до** reduce-стадии, это сэконмит ресурсы reducer'ов. Для этого существет **combiner**. Его формальная модель такая же, как и у reducer'a: `(k, v1), (k, v2) -> (k, [v1, v2])`, но реализация имеет 2 отличия:
* combiner вызывается на выходе одного маппера,
* система не даёт гарантий, сколько раз выполнится combiner и выполнится вообще.

*Нужен ли combiner в нашем примере? Каким он может быть?

#### 5. Объединение нескольких задач
В реальной жизни Hadoop-программы состоят из большого кол-ва задач, которые выполняются в разной последовательности и образуют направленный граф вычислений (DAG). Побробуем отсортировать слова по частоте встречаемости. 

Исходник: /home/velkerr/sber-hadoop2021-1/materials/02-mapreduce/03-chaining/run.sh

#### 6. Задача
Отфильтровать стоп-слова при подсчёте слов. Стоп-слова находятся в `/datasets/stop_words_en.txt`. Для работы с файлом в рамках задачи, его нужно добавить в DistributedCache.

#### 7. Счетчики в Hadoop
 - ещё 1 возможность отладки
 - возможность в некоторых случаях избежать редьюсера.
 
Исходник: `/home/velkerr/sber-hadoop2021-1/materials/02-mapreduce/06-counters`

Объявление счётчика в Python3: `print("reporter:counter:Wiki stats,Stop words,{}".format(1), file=sys.stderr)`
* `reporter:counter:` - объявление счетчика
* `Wiki stats` - группа счетчиков
* `Stop words` - название счетчика

#### 8. Задача. Подсчёт числа PI.
Оценить значение числа PI методом Монте Карло. 

[Статья на Хабре](https://habr.com/ru/post/128454/)

Исходник: `/home/velkerr/sber-hadoop2021-1/materials/02-mapreduce/07_pi_stub`

